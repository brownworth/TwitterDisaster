{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring changes in related words over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will show how words related to a particular word will change over time deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from math import ceil\n",
    "import string\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tweet_id','timestamp','tweet_text','user_id',\n",
    "           'tweet_coords','tweet_coords_list','tweet_long','tweet_lat','location',\n",
    "           'enc_url','tweet_lang','hashtags']\n",
    "tweet_full = pd.read_csv(r'./tweetCoords.csv',\n",
    "                         header=None,\n",
    "                         names=columns,\n",
    "                         parse_dates=[1],\n",
    "                         infer_datetime_format=True,\n",
    "                         index_col='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writing a custom text cleaner. Currently configured to remove all punctuation, _except #_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stops = stopwords.words('english')\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True,preserve_case=False,reduce_len=True)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "#     takes input string and converts or removes characters depending on settings.\n",
    "#     returns a string\n",
    "#     convert case:\n",
    "    tweet = tweet.lower()\n",
    "#     remove URLs:\n",
    "    tweet = re.sub('https?://\\S+','',tweet)\n",
    "#     remove @mentions, including those with a leading '-' or '.' : \n",
    "    tweet = re.sub('[-\\.]?@\\w+','',tweet)\n",
    "#     remove punctuation, but not hashtags:\n",
    "    tweet = tweet.translate(tweet.maketrans('','',string.punctuation.replace(\"#\",\"\")))\n",
    "#     remove non-hashtag '#'.\n",
    "    tweet = re.sub('#\\B','',tweet)\n",
    "#     remove 'amp', 'gt', 'lt', indicating decoded ampersand, greater-than, less-than characters\n",
    "    tweet = re.sub(r'\\b(amp|gt|lt)\\b','',tweet)\n",
    "#     remove punctuation, including hashtags:\n",
    "#     tweet = tweet.translate(tweet.maketrans('','',string.punctuation))\n",
    "    return tweet\n",
    "\n",
    "def tokens_no_stopwords(tweet_as_string):\n",
    "#     wrapper function that combines the tokenizer, cleaner, and stopword removal.\n",
    "#     takes a string and returns a list of strings\n",
    "    cleaned_tweet = clean_tweet(tweet_as_string)\n",
    "    tweet_as_tokens = tweet_tokenizer.tokenize(cleaned_tweet)\n",
    "    tweet_no_stops = [word for word in tweet_as_tokens if word not in tweet_stops]\n",
    "    \n",
    "    return tweet_no_stops\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tweetlt', 'withgtamp', '#stuff', '#in']\n"
     ]
    }
   ],
   "source": [
    "re_text = \"this is ! A TWEETlt withgtamp @some .@random amp gt lt @@extra #stuff ##in IT!?@>#! \"\n",
    "print(tokens_no_stopwords(re_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "florida            2257\n",
       "#hurricaneirma     1980\n",
       "#irma              1585\n",
       "irma               1537\n",
       "reports            1387\n",
       "hurricane          1344\n",
       "fl                 1295\n",
       "mph                1177\n",
       "asos               1118\n",
       "gust               1076\n",
       "power              1030\n",
       "knots              1027\n",
       "de                  749\n",
       "storm               731\n",
       "wind                714\n",
       "miami               684\n",
       "rain                662\n",
       "beach               621\n",
       "still               607\n",
       "safe                575\n",
       "en                  568\n",
       "like                565\n",
       "county              553\n",
       "get                 493\n",
       "n                   467\n",
       "us                  427\n",
       "pm                  426\n",
       "go                  426\n",
       "good                402\n",
       "#florida            398\n",
       "                   ... \n",
       "formar                1\n",
       "pusssy                1\n",
       "muda                  1\n",
       "#ironmanflorida       1\n",
       "pesimista             1\n",
       "82817                 1\n",
       "subconciously         1\n",
       "tonga                 1\n",
       "#jagsgotrobbed        1\n",
       "#zombies              1\n",
       "cheat                 1\n",
       "highlighted           1\n",
       "#parttime             1\n",
       "#escapefromfla        1\n",
       "flakes                1\n",
       "adm                   1\n",
       "respira               1\n",
       "grovebtp              1\n",
       "calcule               1\n",
       "#enoughsaid           1\n",
       "washintonia           1\n",
       "doesnt                1\n",
       "#chill                1\n",
       "busccb                1\n",
       "#comeinside           1\n",
       "crutches              1\n",
       "disappear             1\n",
       "#ravennation          1\n",
       "willl                 1\n",
       "#waterytart           1\n",
       "Length: 23088, dtype: int64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_full.loc[\"2017-09-10 09:00:00\":\"2017-09-11 09:00:00\",'tweet_text'].apply(tokens_no_stopwords).apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the word we're comparing similarity to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"irma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting here, begin the iteration over times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_words = pd.DataFrame()\n",
    "tweet_date = pd.to_datetime(\"2017-09-10 00:00:00\")\n",
    "date_delta = pd.Timedelta(\"24HR\")\n",
    "end_date = pd.to_datetime(\"2017-09-10 00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_num_words = 20 # number of words to include in cosine similarity ordered list\n",
    "pct_occ_thresh = .01 # words must occur a number of times >= this percent of number of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of words from this time frame, based upon the occurrence threshold above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "florida           2257\n",
       "#hurricaneirma    1980\n",
       "#irma             1585\n",
       "irma              1537\n",
       "reports           1387\n",
       "hurricane         1344\n",
       "fl                1295\n",
       "mph               1177\n",
       "asos              1118\n",
       "gust              1076\n",
       "power             1030\n",
       "knots             1027\n",
       "de                 749\n",
       "storm              731\n",
       "wind               714\n",
       "miami              684\n",
       "rain               662\n",
       "beach              621\n",
       "still              607\n",
       "safe               575\n",
       "en                 568\n",
       "like               565\n",
       "county             553\n",
       "get                493\n",
       "n                  467\n",
       "us                 427\n",
       "pm                 426\n",
       "go                 426\n",
       "good               402\n",
       "#florida           398\n",
       "                  ... \n",
       "winds              354\n",
       "back               350\n",
       "que                349\n",
       "going              346\n",
       "#hurricane         344\n",
       "got                343\n",
       "house              339\n",
       "time               330\n",
       "people             320\n",
       "la                 316\n",
       "one                314\n",
       "se                 314\n",
       "getting            301\n",
       "love               291\n",
       "everyone           286\n",
       "today              286\n",
       "update             283\n",
       "warning            277\n",
       "2                  266\n",
       "#hurrcaneirma      262\n",
       "st                 259\n",
       "ese                256\n",
       "day                256\n",
       "see                256\n",
       "thank              255\n",
       "west               243\n",
       "know               241\n",
       "palm               238\n",
       "tampa              238\n",
       "shit               236\n",
       "Length: 69, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tweets = len(tweet_full.loc[tweet_date:tweet_date+date_delta])\n",
    "min_count = ceil(num_tweets * pct_occ_thresh)\n",
    "tweet_words = tweet_full.loc[\"2017-09-10 09:00:00\":\"2017-09-11 09:00:00\",'tweet_text'].apply(tokens_no_stopwords)\n",
    "word_counts = tweet_words.apply(pd.Series).stack().value_counts()\n",
    "word_counts[word_counts > min_count]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently there is an incompatibility between gensim and numpy > 1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-10 00:00:00: 22953 tweets (230 occurrence threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brown/.local/share/virtualenvs/TwitterDisaster-4Cppn-LV/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for tweet_day in pd.date_range(start = tweet_date, end = end_date, freq = date_delta):\n",
    "    tweet_text = tweet_full.loc[tweet_day:tweet_day + date_delta,\"tweet_text\"]\n",
    "    min_count = ceil(len(tweet_text) * pct_occ_thresh)\n",
    "#     this line is just here for diagnostic purposes.\n",
    "#     print(str(tweet_day)+\": \"+str(len(tweet_text))+\" tweets (\"+str(min_count)+\" occurrence threshold)\") \n",
    "\n",
    "    tweets_tokens = tweet_text.apply(tokens_no_stopwords)\n",
    "    vector_model = Word2Vec(tweets_tokens, min_count=min_count, sg=1, window=5, workers=5, size=100)\n",
    "    word_matrix = vector_model.wv[vector_model.wv.vocab]\n",
    "#     tsne = TSNE(n_components=2)\n",
    "#     result = tsne.fit_transform(word_matrix)\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(word_matrix)\n",
    "\n",
    "    terms_from_range = pd.DataFrame.from_records(vector_model.wv.most_similar(search_term,topn=top_num_words),columns=[tweet_day,\"Cos_Sim\"])\n",
    "    related_words = pd.concat([related_words,terms_from_range],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_model.wv.get_vector(\"storm\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_model.wv.similarity(\"storm\",\"rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>Cos_Sim</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>Cos_Sim</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>Cos_Sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#florida</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>florida</td>\n",
       "      <td>0.995977</td>\n",
       "      <td>#irma</td>\n",
       "      <td>0.997512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#miami</td>\n",
       "      <td>0.997051</td>\n",
       "      <td>#florida</td>\n",
       "      <td>0.995077</td>\n",
       "      <td>#florida</td>\n",
       "      <td>0.996473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#irma</td>\n",
       "      <td>0.996905</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>0.992538</td>\n",
       "      <td>florida</td>\n",
       "      <td>0.995982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>county</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>#irma</td>\n",
       "      <td>0.991577</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>0.989949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#hurricane</td>\n",
       "      <td>0.994259</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>0.991269</td>\n",
       "      <td>go</td>\n",
       "      <td>0.989405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>0.994060</td>\n",
       "      <td>#miami</td>\n",
       "      <td>0.991052</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>0.987133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>us</td>\n",
       "      <td>0.992967</td>\n",
       "      <td>everyone</td>\n",
       "      <td>0.989209</td>\n",
       "      <td>get</td>\n",
       "      <td>0.986102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stay</td>\n",
       "      <td>0.992179</td>\n",
       "      <td>orlando</td>\n",
       "      <td>0.988180</td>\n",
       "      <td>got</td>\n",
       "      <td>0.985505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>get</td>\n",
       "      <td>0.991825</td>\n",
       "      <td>get</td>\n",
       "      <td>0.987675</td>\n",
       "      <td>#miami</td>\n",
       "      <td>0.985052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like</td>\n",
       "      <td>0.991686</td>\n",
       "      <td>time</td>\n",
       "      <td>0.985066</td>\n",
       "      <td>doral</td>\n",
       "      <td>0.984814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>back</td>\n",
       "      <td>0.990889</td>\n",
       "      <td>one</td>\n",
       "      <td>0.984768</td>\n",
       "      <td>orlando</td>\n",
       "      <td>0.982818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>house</td>\n",
       "      <td>0.990584</td>\n",
       "      <td>power</td>\n",
       "      <td>0.984497</td>\n",
       "      <td>everyone</td>\n",
       "      <td>0.982632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>orlando</td>\n",
       "      <td>0.990495</td>\n",
       "      <td>going</td>\n",
       "      <td>0.984468</td>\n",
       "      <td>disney</td>\n",
       "      <td>0.981479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>everyone</td>\n",
       "      <td>0.990454</td>\n",
       "      <td>love</td>\n",
       "      <td>0.983288</td>\n",
       "      <td>house</td>\n",
       "      <td>0.981104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>florida</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>still</td>\n",
       "      <td>0.983012</td>\n",
       "      <td>love</td>\n",
       "      <td>0.980621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>people</td>\n",
       "      <td>0.989638</td>\n",
       "      <td>people</td>\n",
       "      <td>0.982887</td>\n",
       "      <td>time</td>\n",
       "      <td>0.980603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>doral</td>\n",
       "      <td>0.989160</td>\n",
       "      <td>shit</td>\n",
       "      <td>0.982485</td>\n",
       "      <td>day</td>\n",
       "      <td>0.980411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>miami</td>\n",
       "      <td>0.987898</td>\n",
       "      <td>day</td>\n",
       "      <td>0.982102</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.980288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>safe</td>\n",
       "      <td>0.987719</td>\n",
       "      <td>see</td>\n",
       "      <td>0.979453</td>\n",
       "      <td>right</td>\n",
       "      <td>0.979566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>one</td>\n",
       "      <td>0.987286</td>\n",
       "      <td>stay</td>\n",
       "      <td>0.979437</td>\n",
       "      <td>see</td>\n",
       "      <td>0.978798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-09-10 00:00:00   Cos_Sim 2017-09-10 00:00:00   Cos_Sim  \\\n",
       "0             #florida  0.998028             florida  0.995977   \n",
       "1               #miami  0.997051            #florida  0.995077   \n",
       "2                #irma  0.996905          #hurricane  0.992538   \n",
       "3               county  0.994796               #irma  0.991577   \n",
       "4           #hurricane  0.994259      #hurricaneirma  0.991269   \n",
       "5       #hurricaneirma  0.994060              #miami  0.991052   \n",
       "6                   us  0.992967            everyone  0.989209   \n",
       "7                 stay  0.992179             orlando  0.988180   \n",
       "8                  get  0.991825                 get  0.987675   \n",
       "9                 like  0.991686                time  0.985066   \n",
       "10                back  0.990889                 one  0.984768   \n",
       "11               house  0.990584               power  0.984497   \n",
       "12             orlando  0.990495               going  0.984468   \n",
       "13            everyone  0.990454                love  0.983288   \n",
       "14             florida  0.990087               still  0.983012   \n",
       "15              people  0.989638              people  0.982887   \n",
       "16               doral  0.989160                shit  0.982485   \n",
       "17               miami  0.987898                 day  0.982102   \n",
       "18                safe  0.987719                 see  0.979453   \n",
       "19                 one  0.987286                stay  0.979437   \n",
       "\n",
       "   2017-09-10 00:00:00   Cos_Sim  \n",
       "0                #irma  0.997512  \n",
       "1             #florida  0.996473  \n",
       "2              florida  0.995982  \n",
       "3           #hurricane  0.989949  \n",
       "4                   go  0.989405  \n",
       "5       #hurricaneirma  0.987133  \n",
       "6                  get  0.986102  \n",
       "7                  got  0.985505  \n",
       "8               #miami  0.985052  \n",
       "9                doral  0.984814  \n",
       "10             orlando  0.982818  \n",
       "11            everyone  0.982632  \n",
       "12              disney  0.981479  \n",
       "13               house  0.981104  \n",
       "14                love  0.980621  \n",
       "15                time  0.980603  \n",
       "16                 day  0.980411  \n",
       "17                safe  0.980288  \n",
       "18               right  0.979566  \n",
       "19                 see  0.978798  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>florida</td>\n",
       "      <td>#irma</td>\n",
       "      <td>florida</td>\n",
       "      <td>florida</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>florida</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>florida</td>\n",
       "      <td>florida</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>us</td>\n",
       "      <td>florida</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>#irma</td>\n",
       "      <td>#miami</td>\n",
       "      <td>florida</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#miami</td>\n",
       "      <td>stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#irma</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#miami</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>stay</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#irma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>everyone</td>\n",
       "      <td>everyone</td>\n",
       "      <td>#miami</td>\n",
       "      <td>#florida</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>miami</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>florida</td>\n",
       "      <td>county</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>power</td>\n",
       "      <td>#miami</td>\n",
       "      <td>safe</td>\n",
       "      <td>safe</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>county</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>#hurricaneirma</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hurricane</td>\n",
       "      <td>going</td>\n",
       "      <td>miami</td>\n",
       "      <td>stay</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>everyone</td>\n",
       "      <td>#miami</td>\n",
       "      <td>#miami</td>\n",
       "      <td>everyone</td>\n",
       "      <td>florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#hurricane</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>everyone</td>\n",
       "      <td>#miami</td>\n",
       "      <td>get</td>\n",
       "      <td>orlando</td>\n",
       "      <td>doral</td>\n",
       "      <td>orlando</td>\n",
       "      <td>county</td>\n",
       "      <td>everyone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>get</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>people</td>\n",
       "      <td>like</td>\n",
       "      <td>doral</td>\n",
       "      <td>stay</td>\n",
       "      <td>safe</td>\n",
       "      <td>miami</td>\n",
       "      <td>#florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#florida</td>\n",
       "      <td>county</td>\n",
       "      <td>stay</td>\n",
       "      <td>county</td>\n",
       "      <td>safe</td>\n",
       "      <td>#hurricane</td>\n",
       "      <td>safe</td>\n",
       "      <td>house</td>\n",
       "      <td>safe</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>like</td>\n",
       "      <td>stay</td>\n",
       "      <td>get</td>\n",
       "      <td>still</td>\n",
       "      <td>everyone</td>\n",
       "      <td>county</td>\n",
       "      <td>get</td>\n",
       "      <td>everyone</td>\n",
       "      <td>like</td>\n",
       "      <td>orlando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stay</td>\n",
       "      <td>still</td>\n",
       "      <td>us</td>\n",
       "      <td>house</td>\n",
       "      <td>go</td>\n",
       "      <td>disney</td>\n",
       "      <td>miami</td>\n",
       "      <td>back</td>\n",
       "      <td>going</td>\n",
       "      <td>power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>going</td>\n",
       "      <td>safe</td>\n",
       "      <td>got</td>\n",
       "      <td>everyone</td>\n",
       "      <td>county</td>\n",
       "      <td>stay</td>\n",
       "      <td>everyone</td>\n",
       "      <td>county</td>\n",
       "      <td>people</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>safe</td>\n",
       "      <td>us</td>\n",
       "      <td>people</td>\n",
       "      <td>us</td>\n",
       "      <td>still</td>\n",
       "      <td>safe</td>\n",
       "      <td>still</td>\n",
       "      <td>us</td>\n",
       "      <td>stay</td>\n",
       "      <td>#miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>go</td>\n",
       "      <td>people</td>\n",
       "      <td>county</td>\n",
       "      <td>back</td>\n",
       "      <td>got</td>\n",
       "      <td>get</td>\n",
       "      <td>us</td>\n",
       "      <td>good</td>\n",
       "      <td>go</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>still</td>\n",
       "      <td>update</td>\n",
       "      <td>power</td>\n",
       "      <td>see</td>\n",
       "      <td>power</td>\n",
       "      <td>power</td>\n",
       "      <td>house</td>\n",
       "      <td>still</td>\n",
       "      <td>good</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time</td>\n",
       "      <td>got</td>\n",
       "      <td>like</td>\n",
       "      <td>time</td>\n",
       "      <td>stay</td>\n",
       "      <td>love</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>getting</td>\n",
       "      <td>get</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>got</td>\n",
       "      <td>back</td>\n",
       "      <td>still</td>\n",
       "      <td>got</td>\n",
       "      <td>back</td>\n",
       "      <td>house</td>\n",
       "      <td>going</td>\n",
       "      <td>get</td>\n",
       "      <td>house</td>\n",
       "      <td>hurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>getting</td>\n",
       "      <td>power</td>\n",
       "      <td>go</td>\n",
       "      <td>power</td>\n",
       "      <td>disney</td>\n",
       "      <td>know</td>\n",
       "      <td>update</td>\n",
       "      <td>power</td>\n",
       "      <td>getting</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>good</td>\n",
       "      <td>house</td>\n",
       "      <td>know</td>\n",
       "      <td>get</td>\n",
       "      <td>us</td>\n",
       "      <td>going</td>\n",
       "      <td>good</td>\n",
       "      <td>got</td>\n",
       "      <td>one</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-09-10 00:00:00 2017-09-10 00:00:00 2017-09-10 00:00:00  \\\n",
       "0       #hurricaneirma               #irma               #irma   \n",
       "1              florida      #hurricaneirma             florida   \n",
       "2                   us             florida      #hurricaneirma   \n",
       "3                #irma            #florida            #florida   \n",
       "4             everyone            everyone              #miami   \n",
       "5                power              #miami                safe   \n",
       "6            hurricane               going               miami   \n",
       "7           #hurricane           hurricane            everyone   \n",
       "8                  get          #hurricane          #hurricane   \n",
       "9             #florida              county                stay   \n",
       "10                like                stay                 get   \n",
       "11                stay               still                  us   \n",
       "12               going                safe                 got   \n",
       "13                safe                  us              people   \n",
       "14                  go              people              county   \n",
       "15               still              update               power   \n",
       "16                time                 got                like   \n",
       "17                 got                back               still   \n",
       "18             getting               power                  go   \n",
       "19                good               house                know   \n",
       "\n",
       "   2017-09-10 00:00:00 2017-09-10 00:00:00 2017-09-10 00:00:00  \\\n",
       "0       #hurricaneirma             florida               #irma   \n",
       "1              florida               #irma            #florida   \n",
       "2                #irma              #miami             florida   \n",
       "3           #hurricane            #florida              #miami   \n",
       "4             #florida          #hurricane               miami   \n",
       "5                 safe      #hurricaneirma      #hurricaneirma   \n",
       "6                 stay           hurricane            everyone   \n",
       "7               #miami                 get             orlando   \n",
       "8               people                like               doral   \n",
       "9               county                safe          #hurricane   \n",
       "10               still            everyone              county   \n",
       "11               house                  go              disney   \n",
       "12            everyone              county                stay   \n",
       "13                  us               still                safe   \n",
       "14                back                 got                 get   \n",
       "15                 see               power               power   \n",
       "16                time                stay                love   \n",
       "17                 got                back               house   \n",
       "18               power              disney                know   \n",
       "19                 get                  us               going   \n",
       "\n",
       "   2017-09-10 00:00:00 2017-09-10 00:00:00 2017-09-10 00:00:00  \\\n",
       "0              florida             florida               #irma   \n",
       "1                #irma               #irma          #hurricane   \n",
       "2             #florida            #florida              #miami   \n",
       "3           #hurricane                stay            #florida   \n",
       "4       #hurricaneirma          #hurricane             florida   \n",
       "5               county      #hurricaneirma      #hurricaneirma   \n",
       "6               #miami              #miami            everyone   \n",
       "7                doral             orlando              county   \n",
       "8                 stay                safe               miami   \n",
       "9                 safe               house                safe   \n",
       "10                 get            everyone                like   \n",
       "11               miami                back               going   \n",
       "12            everyone              county              people   \n",
       "13               still                  us                stay   \n",
       "14                  us                good                  go   \n",
       "15               house               still                good   \n",
       "16           hurricane             getting                 get   \n",
       "17               going                 get               house   \n",
       "18              update               power             getting   \n",
       "19                good                 got                 one   \n",
       "\n",
       "   2017-09-10 00:00:00  \n",
       "0           #hurricane  \n",
       "1       #hurricaneirma  \n",
       "2                 stay  \n",
       "3                #irma  \n",
       "4               county  \n",
       "5                 like  \n",
       "6              florida  \n",
       "7             everyone  \n",
       "8             #florida  \n",
       "9                house  \n",
       "10             orlando  \n",
       "11               power  \n",
       "12                safe  \n",
       "13              #miami  \n",
       "14                 get  \n",
       "15                 got  \n",
       "16                  us  \n",
       "17           hurricane  \n",
       "18                 one  \n",
       "19               right  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_words.iloc[:,0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_text[(tweet_text.str.contains(r\"\\bstorm\\b\",regex=True)) & (tweet_text.str.contains(r\"\\bdamage\\b\",regex=True))].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_text[(tweet_text.str.contains(r\"\\bstorm\\b\",regex=True)) & (tweet_text.str.contains(r\"\\bhelping\\b\",regex=True))].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing words to hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2017-09-01 02:42:56    @matt_swag1  amp  _its_guwap TURNIN UP TO MY #...\n",
       "2017-09-01 03:19:14    being bae today and running errands with her w...\n",
       "2017-09-01 04:24:25    FULL VIDEO IN MY BIO  lt ---          #Benzo o...\n",
       "2017-09-01 04:49:28    Summer 1997  lt  Summer 2017  minus the Nazi s...\n",
       "2017-09-01 08:16:10    In my head  lt 3 en I m Not Lost I m RVing htt...\n",
       "2017-09-01 09:01:16    In my head  lt 3 en I m Not Lost I m RVing htt...\n",
       "2017-09-01 13:54:16                   introducing yourself in class  lt \n",
       "2017-09-01 14:59:08    Reminder:   gt  gt  Labor Day is on Monday, Se...\n",
       "2017-09-01 15:45:23    The Danger that Lies Within  Diet  Foods... ht...\n",
       "2017-09-01 16:53:56    John Kelly considered resigning after Comey wa...\n",
       "2017-09-01 17:53:34    @FoxBusiness @CharlesHurt Straight-thinking Ch...\n",
       "2017-09-01 22:17:37    E d_Mobarek to all the muselmans poeple  lt 3 ...\n",
       "2017-09-02 15:06:57    When your favorite bartender isnt in the clubh...\n",
       "2017-09-02 17:39:17    i just saw this im such a great person. ily  l...\n",
       "2017-09-02 18:46:03    bringing the fall season in early with dollywa...\n",
       "2017-09-02 19:39:54     lt  lt Smooth Cri N@L gt  gt  i ll getchya 9 ...\n",
       "2017-09-02 20:08:37              @realmandyrain 2 Beautiful Ladys   lt 3\n",
       "2017-09-02 22:05:53           @lindeelink U look Beyond Beautiful   lt 3\n",
       "2017-09-03 01:40:08    Suprised this beautiful girl today  lt 3 https...\n",
       "2017-09-03 02:04:38    @nafiakhan1 You are glowing, mA     lt 3 So ex...\n",
       "2017-09-03 02:13:20                  Word.  lt 3 https://t.co/lsgsoxRaKX\n",
       "2017-09-03 02:34:29    No lie, @TheFieryFox makes the best bak lava h...\n",
       "2017-09-03 03:30:40     @Larkawuff OMG please get em. We can match  lt 3\n",
       "2017-09-03 07:08:00    Finding out things I never wanted to know lt  ...\n",
       "2017-09-03 15:19:11    @mattrosell Im crying in the club right now  l...\n",
       "2017-09-03 15:21:23    When in doubt, hype it up   lt /sarcasm gt  ht...\n",
       "2017-09-03 16:28:12    .@DWStweets .@RepDWStweets   lt    #LockHerUp ...\n",
       "2017-09-03 16:30:49    @meanpIastic Very cool but I could never ride ...\n",
       "2017-09-03 17:34:49    @a40OZofKARLiTO Seriously ily keep reminiscing...\n",
       "2017-09-03 18:26:45    Magic Kingdom with my Prince Charming lt 3 #di...\n",
       "                                             ...                        \n",
       "2017-10-07 20:12:23                            @xobabyjo Incorrect  lt 3\n",
       "2017-10-07 21:17:07    Here s how a  fu lt king moron  celebrates His...\n",
       "2017-10-07 23:11:22                         lt 3 https://t.co/S6qsqqqzAg\n",
       "2017-10-07 23:58:01    Dissin the same nigga you smiling in pics with...\n",
       "2017-10-08 03:04:57                   @Skylar_Eventive  lt 3  lt 3  lt 3\n",
       "2017-10-08 12:26:57    @lindeelink Just bought Someday on Amazon Lind...\n",
       "2017-10-08 17:02:17    And Tillerson created  fu lt kin  moron . So m...\n",
       "2017-10-08 17:32:16    @JonnieBaker7 Go back into your hole #TwitterT...\n",
       "2017-10-08 19:19:22     lt  lt  You don t need to be perfect to be go...\n",
       "2017-10-08 19:20:40             @jarvisthecpu Get us matchin pairs  lt 3\n",
       "2017-10-08 19:34:19                   Phat asses  gt   lt  Juicy Titties\n",
       "2017-10-08 21:16:08    Me gustabas pq eras distinto... ahora eres igu...\n",
       "2017-10-09 00:17:01    Supporting local music   :  Hangin  with THIS ...\n",
       "2017-10-09 01:36:38    i love when my friends travel down south to se...\n",
       "2017-10-09 02:41:03    People who only reach out to you when it s con...\n",
       "2017-10-09 04:25:37    ur always confusin sis but  lt 3 u https://t.c...\n",
       "2017-10-09 14:05:04    This is why I hop around to my family member  ...\n",
       "2017-10-09 14:30:35    Let your dreams be bigger then your fears, and...\n",
       "2017-10-09 18:11:42    gettin a good nod in at work   lt  gt  gt  gt ...\n",
       "2017-10-09 20:34:54     lt SWIPE gt  Trophy Wife      #prettyBaby #me...\n",
       "2017-10-09 21:33:01    #GSOTD  #Gym Song of the Day :  I  lt 3 EC2  -...\n",
       "2017-10-10 01:30:43    Sad for my #seminoles it s been a rough year  ...\n",
       "2017-10-10 02:19:56    H A P P Y  B I R T H D A Y   j.j_loretto #brot...\n",
       "2017-10-10 03:28:24    prayers for Christian s family and to those st...\n",
       "2017-10-10 09:57:38    @corbynbesson November 8 is my birthday so can...\n",
       "2017-10-10 10:37:00                         lt 3 https://t.co/cYlXAT1b1Z\n",
       "2017-10-10 14:19:08    A baby is a beautiful blessing  lt 3 With Jess...\n",
       "2017-10-10 16:39:08    Los dramas y griter os de toda mi familia junt...\n",
       "2017-10-10 20:45:06     @Impeach_D_Trump Stand by your fu lt king moron.\n",
       "2017-10-10 23:51:51                       @digamecampos mucho amor  lt 3\n",
       "Name: tweet_text, Length: 465, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_full[tweet_full.tweet_text.str.contains(\"\\\\blt\\\\b\")].tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = tweet_full.loc[\"2017-09-10 09:00:00\":\"2017-09-11 09:00:00\"].tweet_text.str.lower().str.split(r'\\s+',expand=True).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_count = word_list[word_list.index.str[0] == '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_words = hashtags_count.index.str[1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the                        5790\n",
       "@                          4370\n",
       "i                          4057\n",
       "to                         3717\n",
       "a                          3586\n",
       "of                         3394\n",
       "in                         3178\n",
       "and                        3034\n",
       "                           2811\n",
       "is                         2761\n",
       "my                         2334\n",
       "florida                    2124\n",
       "this                       2011\n",
       "s                          1948\n",
       "#hurricaneirma             1913\n",
       "for                        1859\n",
       "from                       1806\n",
       "you                        1741\n",
       "it                         1612\n",
       "we                         1607\n",
       "on                         1543\n",
       "#irma                      1527\n",
       "at                         1505\n",
       "reports                    1386\n",
       "t                          1351\n",
       "irma                       1289\n",
       "hurricane                  1257\n",
       "are                        1166\n",
       "mph                        1160\n",
       "asos                       1118\n",
       "                           ... \n",
       "season...                     1\n",
       "ndolos                        1\n",
       "@wnba                         1\n",
       "grrr                          1\n",
       "14:57                         1\n",
       "hawk                          1\n",
       "@miamidolphins                1\n",
       "finn                          1\n",
       "#palmaire                     1\n",
       "https://t.co/2xoetp7r1r       1\n",
       "https://t.co/bemffcoscq       1\n",
       "https://t.co/kfhv9tjues       1\n",
       "https://t.co/lytyczbpuh       1\n",
       "https://t.co/ldtx3mnyd6       1\n",
       "https://t.co/kpv3eoycbl       1\n",
       "https://t.co/dfbi3dlxdj       1\n",
       "#teelingwhiskey               1\n",
       "https://t.co/o0evrh0jzw       1\n",
       "https://t.co/6dzpwf4uj0       1\n",
       "https://t.co/3nrxtbagpn       1\n",
       "tanto,                        1\n",
       "https://t.co/dwxaxcyxqw       1\n",
       "stang                         1\n",
       "tomada                        1\n",
       "#interconmiami                1\n",
       "loooud                        1\n",
       "4yr                           1\n",
       "town....                      1\n",
       "https://t.co/aggs23oduy       1\n",
       "umbrella.                     1\n",
       "Length: 45446, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list['#hurricaneirma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['.@mayorgimenez', '.@cbs12', '.@flashgjr', '.@10newswtsp',\n",
       "       '.@richarddymond', '.@drtiajolie', '#@abc', '.@realdonaldtrump',\n",
       "       '.@andrewwulfeck:', '.@occc', '.@rborn83,', '.@miamidadecounty',\n",
       "       '.@manateesheriff', '.@deadpool1973', '-@notcampbellmatt',\n",
       "       '.@dukeenergy', '.@miamidadefire', '-@grant_gilmore', '.@jimsmallman',\n",
       "       '.@thecwsupergirl', 'w@30.', '.@goabode', 'l@s', '.@jason_lanning',\n",
       "       '.@tampaelectric', '.@nicoleebryan', '.@potus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[word_list.index.str[1]=='@'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                   2811.0\n",
       "my                                 2334.0\n",
       "florida                            2124.0\n",
       "this                               2011.0\n",
       "you                                1741.0\n",
       "it                                 1612.0\n",
       "we                                 1607.0\n",
       "irma                               1289.0\n",
       "hurricane                          1257.0\n",
       "gust                               1074.0\n",
       "me                                  952.0\n",
       "power                               878.0\n",
       "fl                                  847.0\n",
       "wind                                656.0\n",
       "storm                               630.0\n",
       "our                                 563.0\n",
       "now                                 524.0\n",
       "rain                                499.0\n",
       "down                                477.0\n",
       "safe                                471.0\n",
       "miami                               468.0\n",
       "go                                  410.0\n",
       "will                                393.0\n",
       "beach                               384.0\n",
       "stay                                360.0\n",
       "tornado                             357.0\n",
       "us                                  345.0\n",
       "got                                 343.0\n",
       "winds                               317.0\n",
       "f                                   313.0\n",
       "                                    ...  \n",
       "fortmyers.                            NaN\n",
       "9september                            NaN\n",
       "doglife                               NaN\n",
       "piperlove                             NaN\n",
       "russiansinflorida                     NaN\n",
       "staybless                             NaN\n",
       "pawpaw                                NaN\n",
       "illinois                              NaN\n",
       "fortpierce,                           NaN\n",
       "uracanirma                            NaN\n",
       "btwwearesafe                          NaN\n",
       "iwon                                  NaN\n",
       "laryngitis#hurricaneirma#losttv       NaN\n",
       "mydailyinspiration                    NaN\n",
       "hotterthanthedevilsdick               NaN\n",
       "vibrantatanyage                       NaN\n",
       "ihateyouirma                          NaN\n",
       "mantra                                NaN\n",
       "itshappening                          NaN\n",
       "cholanews                             NaN\n",
       "gobucs                                NaN\n",
       "emcee                                 NaN\n",
       "expeditioneverest                     NaN\n",
       "loveislove                            NaN\n",
       "bibliotherapy                         NaN\n",
       "irma.ahora                            NaN\n",
       "lonelyplanet                          NaN\n",
       "palmaire                              NaN\n",
       "teelingwhiskey                        NaN\n",
       "interconmiami                         NaN\n",
       "Length: 4690, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[hashtag_words].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = list(combinations(list(vector_model.wv.vocab.keys()),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in word_pairs:\n",
    "    edge_weight = vector_model.wv.similarity(pair[0],pair[1])\n",
    "    if edge_weight > .80:\n",
    "        tweet_graph.add_edge(pair[0],pair[1],weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_graph.add_nodes_from(vector_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(tweet_graph,path=r'./tweet_graph.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
