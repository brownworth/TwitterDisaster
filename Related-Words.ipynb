{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring changes in related words over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook will show how words related to a particular word will change over time deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from math import ceil\n",
    "import string\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tweet_id','timestamp','tweet_text','user_id',\n",
    "           'tweet_coords','tweet_coords_list','tweet_long','tweet_lat','location',\n",
    "           'enc_url','tweet_lang','hashtags']\n",
    "tweet_full = pd.read_csv(r'./tweetCoords.csv',\n",
    "                         header=None,\n",
    "                         names=columns,\n",
    "                         parse_dates=[1],\n",
    "                         infer_datetime_format=True,\n",
    "                         index_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stops = stopwords.words('english')\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True,preserve_case=False,reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writing a custom text cleaner. Currently configured to remove all punctuation, _except #_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "#     convert case:\n",
    "    tweet = tweet.lower()\n",
    "#     remove URLs:\n",
    "    tweet = re.sub('https?://\\S+','',tweet)\n",
    "#     remove @mentions, including those with a leading '-' or '.' : \n",
    "    tweet = re.sub('[-\\.]?@\\w+','',tweet)\n",
    "#     remove punctuation, but not hashtags:\n",
    "    tweet = tweet.translate(tweet.maketrans('','',string.punctuation.replace(\"#\",\"\")))\n",
    "#     remove non-hashtag '#'.\n",
    "    tweet = re.sub('#\\B','',tweet)\n",
    "#     remove punctuation, including hashtags:\n",
    "#     tweet = tweet.translate(tweet.maketrans('','',string.punctuation))\n",
    "    return tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is  a tweet with    #stuff #in it \n"
     ]
    }
   ],
   "source": [
    "re_text = \"this is ! A TWEET with @some .@random @@extra #stuff ##in IT!?@>#! \"\n",
    "print(clean_tweet(re_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the word we're comparing similarity to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"irma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting here, begin the iteration over times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_words = pd.DataFrame()\n",
    "tweet_date = pd.to_datetime(\"2017-09-10 00:00:00\")\n",
    "date_delta = pd.Timedelta(\"24HR\")\n",
    "end_date = pd.to_datetime(\"2017-09-11 00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_num_words = 20 # number of words to include in cosine similarity ordered list\n",
    "pct_occ_thresh = .001 # words must occur a number of times >= this percent of number of tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently there is an incompatibility between gensim and numpy > 1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-10 00:00:00: 22953 tweets (23 occurrence threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brown/.local/share/virtualenvs/TwitterDisaster-4Cppn-LV/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-09-11 00:00:00: 16322 tweets (17 occurrence threshold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brown/.local/share/virtualenvs/TwitterDisaster-4Cppn-LV/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for tweet_day in pd.date_range(start = tweet_date, end = end_date, freq = date_delta):\n",
    "    \n",
    "    tweet_text = tweet_full.loc[tweet_day:tweet_day + date_delta,\"tweet_text\"]\n",
    "    min_count = ceil(len(tweet_text) * pct_occ_thresh)\n",
    "    print(str(tweet_day)+\": \"+str(len(tweet_text))+\" tweets (\"+str(min_count)+\" occurrence threshold)\") # this line is just here for diagnostic purposes.\n",
    "    \n",
    "    tweets_tokens = tweet_text.apply(lambda x: [clean_tweet(word) for word in tweet_tokenizer.tokenize(x) if word not in tweet_stops])\n",
    "    \n",
    "    vector_model = Word2Vec(tweets_tokens, min_count=min_count, sg=1, window=7)\n",
    "    word_matrix = vector_model.wv[vector_model.wv.vocab]\n",
    "    pca = PCA(n_components=2)\n",
    "    result = pca.fit_transform(word_matrix)\n",
    "    terms_from_range = pd.DataFrame.from_records(vector_model.wv.most_similar(search_term,topn=top_num_words),columns=[tweet_day,\"Cos_Sim\"])\n",
    "    related_words = pd.concat([related_words,terms_from_range],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_model.wv.get_vector(\"storm\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_model.wv.similarity(\"storm\",\"rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>Score</th>\n",
       "      <th>2017-09-11 00:00:00</th>\n",
       "      <th>Score</th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>Score</th>\n",
       "      <th>2017-09-11 00:00:00</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ready</td>\n",
       "      <td>0.798150</td>\n",
       "      <td>post</td>\n",
       "      <td>0.939864</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.756712</td>\n",
       "      <td>post</td>\n",
       "      <td>0.910927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>waiting</td>\n",
       "      <td>0.784966</td>\n",
       "      <td>#hurricaneimra</td>\n",
       "      <td>0.899409</td>\n",
       "      <td>hit</td>\n",
       "      <td>0.746316</td>\n",
       "      <td>#hurricaneimra</td>\n",
       "      <td>0.866769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.780940</td>\n",
       "      <td>survived</td>\n",
       "      <td>0.886995</td>\n",
       "      <td>9</td>\n",
       "      <td>0.739459</td>\n",
       "      <td>#irmahurricane2017</td>\n",
       "      <td>0.861776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.766008</td>\n",
       "      <td>aftermath</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>plan</td>\n",
       "      <td>0.722768</td>\n",
       "      <td>affected</td>\n",
       "      <td>0.861527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit</td>\n",
       "      <td>0.747328</td>\n",
       "      <td>#naples</td>\n",
       "      <td>0.861007</td>\n",
       "      <td>#hurricanirma</td>\n",
       "      <td>0.720597</td>\n",
       "      <td>bye</td>\n",
       "      <td>0.860845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#hurricanirma</td>\n",
       "      <td>0.739417</td>\n",
       "      <td>hotel</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>#hurricaineirma</td>\n",
       "      <td>0.716046</td>\n",
       "      <td>cat</td>\n",
       "      <td>0.854893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#huricaneirma</td>\n",
       "      <td>0.735558</td>\n",
       "      <td>911</td>\n",
       "      <td>0.850783</td>\n",
       "      <td>hits</td>\n",
       "      <td>0.707358</td>\n",
       "      <td>#hurricanirma</td>\n",
       "      <td>0.853060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#goawayirma</td>\n",
       "      <td>0.730663</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.850201</td>\n",
       "      <td>#irma</td>\n",
       "      <td>0.700583</td>\n",
       "      <td>#irmageddon</td>\n",
       "      <td>0.851231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#hurricaineirma</td>\n",
       "      <td>0.724643</td>\n",
       "      <td>affected</td>\n",
       "      <td>0.849157</td>\n",
       "      <td>mayor</td>\n",
       "      <td>0.699137</td>\n",
       "      <td>internet</td>\n",
       "      <td>0.848135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>closer</td>\n",
       "      <td>0.722545</td>\n",
       "      <td>#irmahurricane</td>\n",
       "      <td>0.846904</td>\n",
       "      <td>cuba</td>\n",
       "      <td>0.696500</td>\n",
       "      <td>thoughts</td>\n",
       "      <td>0.847423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mayor</td>\n",
       "      <td>0.718612</td>\n",
       "      <td>#afterirma</td>\n",
       "      <td>0.845050</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.692036</td>\n",
       "      <td>survived</td>\n",
       "      <td>0.847380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#irma</td>\n",
       "      <td>0.718292</td>\n",
       "      <td>bye</td>\n",
       "      <td>0.842413</td>\n",
       "      <td>september</td>\n",
       "      <td>0.690716</td>\n",
       "      <td>passing</td>\n",
       "      <td>0.843138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>latest</td>\n",
       "      <td>0.715709</td>\n",
       "      <td>live</td>\n",
       "      <td>0.841922</td>\n",
       "      <td>live</td>\n",
       "      <td>0.689783</td>\n",
       "      <td>super</td>\n",
       "      <td>0.842892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>path</td>\n",
       "      <td>0.715117</td>\n",
       "      <td>praying</td>\n",
       "      <td>0.840389</td>\n",
       "      <td>internet</td>\n",
       "      <td>0.689123</td>\n",
       "      <td>town</td>\n",
       "      <td>0.842420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>almost</td>\n",
       "      <td>0.713381</td>\n",
       "      <td>#irmahurricane2017</td>\n",
       "      <td>0.839299</td>\n",
       "      <td>closer</td>\n",
       "      <td>0.688849</td>\n",
       "      <td>#prayforflorida</td>\n",
       "      <td>0.842084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hotel</td>\n",
       "      <td>0.712436</td>\n",
       "      <td>wrath</td>\n",
       "      <td>0.838319</td>\n",
       "      <td>electric</td>\n",
       "      <td>0.688269</td>\n",
       "      <td>sound</td>\n",
       "      <td>0.840456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>drive</td>\n",
       "      <td>0.711907</td>\n",
       "      <td>world</td>\n",
       "      <td>0.838067</td>\n",
       "      <td>24</td>\n",
       "      <td>0.687110</td>\n",
       "      <td>#blessed</td>\n",
       "      <td>0.840369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>flooded</td>\n",
       "      <td>0.711849</td>\n",
       "      <td>left</td>\n",
       "      <td>0.836971</td>\n",
       "      <td>waiting</td>\n",
       "      <td>0.686164</td>\n",
       "      <td>#irmahurricane</td>\n",
       "      <td>0.836577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>plan</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>thanks</td>\n",
       "      <td>0.835583</td>\n",
       "      <td>ready</td>\n",
       "      <td>0.685412</td>\n",
       "      <td>party</td>\n",
       "      <td>0.835534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>0.709133</td>\n",
       "      <td>sweet</td>\n",
       "      <td>0.832151</td>\n",
       "      <td>#photo</td>\n",
       "      <td>0.682487</td>\n",
       "      <td>aftermath</td>\n",
       "      <td>0.834480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-09-10 00:00:00     Score 2017-09-11 00:00:00     Score  \\\n",
       "0                ready  0.798150                post  0.939864   \n",
       "1              waiting  0.784966      #hurricaneimra  0.899409   \n",
       "2                 2017  0.780940            survived  0.886995   \n",
       "3                    4  0.766008           aftermath  0.885714   \n",
       "4                  hit  0.747328             #naples  0.861007   \n",
       "5        #hurricanirma  0.739417               hotel  0.857625   \n",
       "6        #huricaneirma  0.735558                 911  0.850783   \n",
       "7          #goawayirma  0.730663             morning  0.850201   \n",
       "8      #hurricaineirma  0.724643            affected  0.849157   \n",
       "9               closer  0.722545      #irmahurricane  0.846904   \n",
       "10               mayor  0.718612          #afterirma  0.845050   \n",
       "11               #irma  0.718292                 bye  0.842413   \n",
       "12              latest  0.715709                live  0.841922   \n",
       "13                path  0.715117             praying  0.840389   \n",
       "14              almost  0.713381  #irmahurricane2017  0.839299   \n",
       "15               hotel  0.712436               wrath  0.838319   \n",
       "16               drive  0.711907               world  0.838067   \n",
       "17             flooded  0.711849                left  0.836971   \n",
       "18                plan  0.711227              thanks  0.835583   \n",
       "19                   9  0.709133               sweet  0.832151   \n",
       "\n",
       "   2017-09-10 00:00:00     Score 2017-09-11 00:00:00     Score  \n",
       "0                 2017  0.756712                post  0.910927  \n",
       "1                  hit  0.746316      #hurricaneimra  0.866769  \n",
       "2                    9  0.739459  #irmahurricane2017  0.861776  \n",
       "3                 plan  0.722768            affected  0.861527  \n",
       "4        #hurricanirma  0.720597                 bye  0.860845  \n",
       "5      #hurricaineirma  0.716046                 cat  0.854893  \n",
       "6                 hits  0.707358       #hurricanirma  0.853060  \n",
       "7                #irma  0.700583         #irmageddon  0.851231  \n",
       "8                mayor  0.699137            internet  0.848135  \n",
       "9                 cuba  0.696500            thoughts  0.847423  \n",
       "10              normal  0.692036            survived  0.847380  \n",
       "11           september  0.690716             passing  0.843138  \n",
       "12                live  0.689783               super  0.842892  \n",
       "13            internet  0.689123                town  0.842420  \n",
       "14              closer  0.688849     #prayforflorida  0.842084  \n",
       "15            electric  0.688269               sound  0.840456  \n",
       "16                  24  0.687110            #blessed  0.840369  \n",
       "17             waiting  0.686164      #irmahurricane  0.836577  \n",
       "18               ready  0.685412               party  0.835534  \n",
       "19              #photo  0.682487           aftermath  0.834480  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-09-10 00:00:00</th>\n",
       "      <th>2017-09-11 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ready</td>\n",
       "      <td>#hurricaneimra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit</td>\n",
       "      <td>#irmahurricane2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plan</td>\n",
       "      <td>hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cuba</td>\n",
       "      <td>aftermath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hits</td>\n",
       "      <td>affected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hotel</td>\n",
       "      <td>live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>waiting</td>\n",
       "      <td>survived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#goawayirma</td>\n",
       "      <td>#afterirma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>update</td>\n",
       "      <td>bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mayor</td>\n",
       "      <td>#naples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>town</td>\n",
       "      <td>#irmahurricane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>#hurricaineirma</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>#irma</td>\n",
       "      <td>#storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>september</td>\n",
       "      <td>#irmageddon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>electric</td>\n",
       "      <td>made</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#hurricanirma</td>\n",
       "      <td>prayers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>national</td>\n",
       "      <td>praying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>coffee</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-09-10 00:00:00 2017-09-11 00:00:00\n",
       "0                 2017                post\n",
       "1                ready      #hurricaneimra\n",
       "2                  hit  #irmahurricane2017\n",
       "3                 plan               hotel\n",
       "4                 cuba           aftermath\n",
       "5                 hits            affected\n",
       "6                    4              family\n",
       "7                hotel                live\n",
       "8              waiting            survived\n",
       "9          #goawayirma          #afterirma\n",
       "10              update                 bye\n",
       "11               mayor             #naples\n",
       "12                town      #irmahurricane\n",
       "13     #hurricaineirma               thank\n",
       "14               #irma              #storm\n",
       "15           september         #irmageddon\n",
       "16            electric                made\n",
       "17       #hurricanirma             prayers\n",
       "18            national             praying\n",
       "19              coffee                 cat"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_words.iloc[:,0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_text[(tweet_text.str.contains(r\"\\bstorm\\b\",regex=True)) & (tweet_text.str.contains(r\"\\bdamage\\b\",regex=True))].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_text[(tweet_text.str.contains(r\"\\bstorm\\b\",regex=True)) & (tweet_text.str.contains(r\"\\bhelping\\b\",regex=True))].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing words to hashtags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = tweet_full.loc[\"2017-09-11 00:00:00\":\"2017-09-12 00:00:00\"].tweet_text.str.lower().str.split(r'\\s+',expand=True).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_count = word_list[word_list.index.str[0] == '#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_words = hashtags_count.index.str[1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list['#hurricaneirma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list[word_list.index.str[1]=='@'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list[hashtag_words].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = list(combinations(list(vector_model.wv.vocab.keys()),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in word_pairs:\n",
    "    edge_weight = vector_model.wv.similarity(pair[0],pair[1])\n",
    "    if edge_weight > .95:\n",
    "        tweet_graph.add_edge(pair[0],pair[1],weight=edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_graph.add_nodes_from(vector_model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(tweet_graph,path=r'./tweet_graph.gexf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
