{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from math import ceil\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import string\n",
    "from math import log10\n",
    "from scipy.stats import norm\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tweet_id','timestamp','tweet_text','user_id',\n",
    "           'tweet_coords','tweet_coords_list','tweet_long','tweet_lat','location',\n",
    "           'enc_url','tweet_lang','hashtags']\n",
    "tweet_full = pd.read_csv(r'./tweetCoords.csv',\n",
    "                         header=None,\n",
    "                         names=columns,\n",
    "                         parse_dates=[1],\n",
    "                         infer_datetime_format=True,\n",
    "                         index_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_words = pd.DataFrame()\n",
    "tweet_date = pd.to_datetime(\"2017-09-10 00:00:00\")\n",
    "date_delta = pd.Timedelta(\"24HR\")\n",
    "end_date = pd.to_datetime(\"2017-09-10 00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_full_en = tweet_full[tweet_full['tweet_lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = tweet_full_en.loc[tweet_date:tweet_date + date_delta,\"tweet_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stops = stopwords.words('english')\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True,preserve_case=False,reduce_len=True)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "#     takes input string and converts or removes characters depending on settings.\n",
    "#     returns a string\n",
    "#     convert case:\n",
    "    tweet = tweet.lower()\n",
    "#     remove URLs:\n",
    "    tweet = re.sub('https?://\\S+','',tweet)\n",
    "#     remove @mentions, including those with a leading '-' or '.' : \n",
    "    tweet = re.sub('[-\\.]?@\\w+','',tweet)\n",
    "#     remove punctuation, but not hashtags:\n",
    "    tweet = tweet.translate(tweet.maketrans('','',string.punctuation.replace(\"#\",\"\")))\n",
    "#     remove non-hashtag '#'.\n",
    "    tweet = re.sub('#\\B','',tweet)\n",
    "#     remove 'amp', 'gt', 'lt', indicating decoded ampersand, greater-than, less-than characters\n",
    "    tweet = re.sub(r'\\b(amp|gt|lt)\\b','',tweet)\n",
    "#     drop numbers and words of < 4 characters.\n",
    "    tweet = re.sub(r'\\b\\w{1,3}\\b','',tweet)\n",
    "    tweet = re.sub(r'\\b\\d+\\b','',tweet)\n",
    "    return tweet\n",
    "\n",
    "def tokens_no_stopwords(tweet_as_string):\n",
    "#     wrapper function that combines the tokenizer, cleaner, and stopword removal.\n",
    "#     takes a string and returns a list of strings\n",
    "    cleaned_tweet = clean_tweet(tweet_as_string)\n",
    "    tweet_as_tokens = tweet_tokenizer.tokenize(cleaned_tweet)\n",
    "    tweet_no_stops = [word for word in tweet_as_tokens if word not in tweet_stops]\n",
    "    \n",
    "    return tweet_no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = tweet_text.str.split(\"\\s+\").apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43387"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the        4900\n",
       "I          4133\n",
       "to         3853\n",
       "@          3337\n",
       "a          3020\n",
       "in         2998\n",
       "and        2843\n",
       "of         2796\n",
       "is         2619\n",
       "           2463\n",
       "for        1977\n",
       "my         1943\n",
       "s          1772\n",
       "you        1647\n",
       "Florida    1592\n",
       "this       1572\n",
       "on         1491\n",
       "t          1357\n",
       "from       1236\n",
       "it         1202\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_reduce_len = TweetTokenizer(reduce_len=True)\n",
    "word_counts_reduce = tweet_text.apply(tweet_reduce_len.tokenize).apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38263"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_reduce.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".          7704\n",
       ",          6587\n",
       "the        4911\n",
       "I          4192\n",
       "to         3866\n",
       "@          3339\n",
       "in         3101\n",
       "a          3043\n",
       "and        2858\n",
       "of         2802\n",
       "is         2644\n",
       "for        1990\n",
       "my         1949\n",
       "s          1787\n",
       "you        1761\n",
       "Florida    1720\n",
       "this       1637\n",
       "FL         1539\n",
       "on         1531\n",
       "t          1374\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_reduce.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_full_tokenizer = tweet_text.apply(tweet_tokenizer.tokenize).apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30594"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_full_tokenizer.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".                 7696\n",
       ",                 6587\n",
       "the               5805\n",
       "i                 4610\n",
       "to                4006\n",
       "@                 3339\n",
       "a                 3324\n",
       "in                3265\n",
       "and               3045\n",
       "of                2860\n",
       "is                2755\n",
       "my                2456\n",
       "this              2302\n",
       "for               2093\n",
       "you               2077\n",
       "s                 1871\n",
       "florida           1805\n",
       "it                1746\n",
       "#hurricaneirma    1631\n",
       "on                1610\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_full_tokenizer.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_full_token_clean = tweet_text.apply(tokens_no_stopwords).apply(pd.Series).stack().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16791"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_full_token_clean.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "florida           1764\n",
       "#hurricaneirma    1633\n",
       "irma              1343\n",
       "hurricane         1294\n",
       "#irma             1199\n",
       "reports            809\n",
       "storm              742\n",
       "#                  685\n",
       "power              679\n",
       "rain               632\n",
       "wind               628\n",
       "like               628\n",
       "safe               619\n",
       "gust               552\n",
       "asos               544\n",
       "beach              532\n",
       "miami              531\n",
       "knots              509\n",
       "county             493\n",
       "still              492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_full_token_clean.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
