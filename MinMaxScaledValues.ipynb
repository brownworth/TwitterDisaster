{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Lists of Words Related to a Specified Search Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This algorithm provides the following:\n",
    "- Imports a dataframe of tweets\n",
    "- Processes tweets and tokenizes words\n",
    "- Uses Word Embeddings to convert words into vectors\n",
    "- Determines related words by using cosine similarity within the vector space\n",
    "- Generates a list, or lists, of words within the time delta(s) selected, ordered by cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imported Libraries\n",
    "Libraries and modules below are used to import and process the tokens into vectors, removing extraneous words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from math import ceil\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import string\n",
    "from math import log10\n",
    "from scipy.stats import norm\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Import\n",
    "Importing and parsing tweets into dataframe, converting the datestamp strings to datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tweet_id','timestamp','tweet_text','user_id',\n",
    "           'tweet_coords','tweet_coords_list','tweet_long','tweet_lat','location',\n",
    "           'enc_url','tweet_lang','hashtags']\n",
    "tweet_full = pd.read_csv(r'./tweetCoords.csv',\n",
    "                         header=None,\n",
    "                         names=columns,\n",
    "                         parse_dates=[1],\n",
    "                         infer_datetime_format=True,\n",
    "                         index_col='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating Tweets by language (english)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_full_en = tweet_full[tweet_full['tweet_lang'] == 'en']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning and Tokenization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stops = stopwords.words('english')\n",
    "tweet_tokenizer = TweetTokenizer(strip_handles=True,preserve_case=False,reduce_len=True)\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "#     takes input string and converts or removes characters depending on settings.\n",
    "#     returns a string\n",
    "#     convert case:\n",
    "    tweet = tweet.lower()\n",
    "#     remove URLs:\n",
    "    tweet = re.sub('https?://\\S+','',tweet)\n",
    "#     remove @mentions, including those with a leading '-' or '.' : \n",
    "    tweet = re.sub('[-\\.]?@\\w+','',tweet)\n",
    "#     remove punctuation, but not hashtags:\n",
    "    tweet = tweet.translate(tweet.maketrans('','',string.punctuation.replace(\"#\",\"\")))\n",
    "#     remove non-hashtag '#'.\n",
    "    tweet = re.sub('#\\B','',tweet)\n",
    "#     remove 'amp', 'gt', 'lt', indicating decoded ampersand, greater-than, less-than characters\n",
    "    tweet = re.sub(r'\\b(amp|gt|lt)\\b','',tweet)\n",
    "#     drop numbers and words of < 4 characters.\n",
    "    tweet = re.sub(r'\\b\\w{1,3}\\b','',tweet)\n",
    "    tweet = re.sub(r'\\b\\d+\\b','',tweet)\n",
    "    return tweet\n",
    "\n",
    "def tokens_no_stopwords(tweet_as_string):\n",
    "#     wrapper function that combines the tokenizer, cleaner, and stopword removal.\n",
    "#     takes a string and returns a list of strings\n",
    "    cleaned_tweet = clean_tweet(tweet_as_string)\n",
    "    tweet_as_tokens = tweet_tokenizer.tokenize(cleaned_tweet)\n",
    "    tweet_no_stops = [word for word in tweet_as_tokens if word not in tweet_stops]\n",
    "    \n",
    "    return tweet_no_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Term\n",
    "This is the term that will serve as the comparison for all later lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"irma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Words Dataframe and Time Deltas\n",
    "This instantiates the dataframe for the related words and specifies the start, end, and time delta for the periods of related words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_words = pd.DataFrame()\n",
    "tweet_date = pd.to_datetime(\"2017-09-10 00:00:00\")\n",
    "date_delta = pd.Timedelta(\"24HR\")\n",
    "end_date = pd.to_datetime(\"2017-09-10 00:00:00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related Word list quantity\n",
    "This number specifies the number of words that will be returned in each list associated with the time periods specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_num_words = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "### Converting Words to Vectors using the 'Word2Vec' library\n",
    "\n",
    "- Iterate through each time period designated above\n",
    "- Apply the tokenization and cleaning functions\n",
    "- Convert the tokens to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    for tweet_day in pd.date_range(start = tweet_date, end = end_date, freq = date_delta):\n",
    "        tweet_text = tweet_full_en.loc[tweet_day:tweet_day + date_delta,\"tweet_text\"]\n",
    "\n",
    "        tweets_tokens = tweet_text.apply(tokens_no_stopwords)\n",
    "#         this line uses the for loop to iterate the minimum word count for inclusion in the vectors:\n",
    "        vector_model = Word2Vec(tweets_tokens, min_count=i, window=7, workers=1, size=100, seed=1, sg=1)\n",
    "#         this line uses the for loop to iterate the context window size for any given word\n",
    "#         vector_model = Word2Vec(tweets_tokens, min_count=1, window=i, workers=1, size=100, seed=1, sg=1)\n",
    "        \n",
    "        word_matrix = vector_model.wv[vector_model.wv.vocab]\n",
    "        vector_model.train(tweets_tokens, total_examples=len(tweet_text), epochs=10)\n",
    "        terms_from_range = pd.DataFrame.from_records(vector_model.wv.most_similar(search_term,topn=top_num_words),\n",
    "                                                     columns=[tweet_day,\"score\"])\n",
    "\n",
    "        related_words = pd.concat([related_words,terms_from_range],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Relationships with Human Coded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the list of related words to identify an Irma Related tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing a list of human coded tweets for 'irma related'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_tweets = pd.read_csv(r'./irma_related_tweets.csv')\n",
    "\n",
    "tweets_on_date = tweet_full_en.loc[tweet_date:tweet_date+date_delta]\n",
    "\n",
    "tweet_encoded = pd.concat([coded_tweets.reset_index(),tweets_on_date.iloc[:-1].reset_index()],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts of human coded Irma related tweets: 0 = not related, 1 = 'irma' related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_encoded_counts = tweet_encoded.loc[:,['tweet_id','timestamp','irma_rel','tweet_text']].groupby('irma_rel').size()\n",
    "print(hc_encoded_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_on_date = tweet_full_en.loc[tweet_date:tweet_date+date_delta]\n",
    "tweet_text = tweets_on_date.tweet_text\n",
    "tweets_tokens = tweet_text.apply(tokens_no_stopwords)\n",
    "#         this line uses the for loop to iterate the minimum word count for inclusion in the vectors:\n",
    "vector_model = Word2Vec(tweets_tokens, min_count=1, window=6, workers=1, size=100, seed=1, sg=1)\n",
    "#         this line uses the for loop to iterate the context window size for any given word\n",
    "#         vector_model = Word2Vec(tweets_tokens, min_count=1, window=i, workers=1, size=100, seed=1, sg=1)\n",
    "        \n",
    "word_matrix = vector_model.wv[vector_model.wv.vocab]\n",
    "vector_model.train(tweets_tokens, total_examples=len(tweet_text), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ScoreTweet(tweet):\n",
    "    tweet_as_terms = tokens_no_stopwords(tweet)\n",
    "    score = 0\n",
    "    for i in tweet_as_terms:\n",
    "        if i in vector_model.wv.vocab:\n",
    "            score += vector_model.wv.similarity(i,search_term)\n",
    "    if len(tweet_as_terms) > 0:\n",
    "        score /= len(tweet_as_terms)\n",
    "    else:\n",
    "        score = 0\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_encoded['Score'] = tweet_encoded.tweet_text.apply(ScoreTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_encoded['MMScore'] = (tweet_encoded['Score'] - tweet_encoded['Score'].min())* 100 / (tweet_encoded['Score'].max() - tweet_encoded['Score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_encoded['MMScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_func_df = pd.DataFrame(np.zeros((101,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(101):\n",
    "    new_func_df.iloc[i] = f1_score(tweet_encoded.irma_rel,tweet_encoded['MMScore'] > i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(new_func_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(tweet_encoded['MMScore'],bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(tweet_encoded[tweet_encoded['MMScore'] > i]) for i in range(101)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(101),[len(tweet_encoded[tweet_encoded['MMScore'] > i])/19088 for i in range(101)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([len(tweet_encoded[tweet_encoded['MMScore'] > i])/19088 for i in range(101)]).to_csv(r'./new_func.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating F1 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to evaluate F1 score for each iteration of the word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_test = pickle.load(open('./pkl_sets/related_words_window_10E.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_words_lists = related_test.iloc[:,0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordsCWScoreList(position,column=0):\n",
    "    related_word_list = list(related_words_lists.iloc[0:position,column])\n",
    "    related_word_list.append(search_term)\n",
    "    return \"|\".join(related_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a numeric position as an input. From there it:\n",
    "- finds all of the words in the cosine-similarity ordered list for the range are at that position or above.\n",
    "- creates a list of those words.\n",
    "- appends the search term to that list.\n",
    "- converts that list to a pipe-delimited string.\n",
    "If the `related_word_list` dataframe has more than one set of related words (as columns) the the second argument allows subsequent columns' lists to be returned.\n",
    "\n",
    "This pipe-delimited string can be used as the input of the `pd.Series.str.contains()` method as a regular expression for matching rows who contain one or more of the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsCWScoreList(10,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purposes of evaluating the effectiveneness of the related words threshold, there are 4 categories of tweets:\n",
    "- human-coded 'irma-related' and the word list is a match (true positive)\n",
    "- human-coded 'not irma-related' and the word list is a match (false positive)\n",
    "- human-coded 'irma-related' and the word list is not a match (false negative)\n",
    "- human-coded 'not irma-related' and the word list is not a match (true negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `score_matrix` dataframe is initialized to be zeroes, to prevent contamination from previous iterations. The following for loop iterates over the `related_words_lists` dataframe from above to evaluate a tweet as related based upon containing one or more words of the subset of the word list for that particular window or minimum count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix = pd.DataFrame(np.zeros(related_words_lists.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(239,5),flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(239,5),flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(239,5),flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(239,5),flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The commented lines should be uncommented for debug purposes.\n",
    "for i in range(0,related_words_lists.shape[1]):\n",
    "#     print(pd.Timestamp.now().time())\n",
    "    for j in range(0,related_words_lists.shape[0]):\n",
    "        score_matrix.iloc[j,i]=f1_score(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(j,i),flags=re.IGNORECASE))   \n",
    "#     print(score_matrix.iloc[j,:])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(score_matrix,open('./score_matrix_seed_term_min_count_10E.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(related_words,open('./related_words_min_count_10E.pkl',\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis on Cosine Similarity Values\n",
    "#### Checking lists of words and F1 scores for effectiveness of analysis based upon similar words contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_graph = related_test.iloc[0:239,10:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_graph.to_csv(r'word_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(word_graph.iloc[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_graph.iloc[:,1] = word_graph.iloc[:,1].apply(log10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_values = word_graph.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_graph.iloc[:,1] = (cos_sim_values - cos_sim_values.min())* 100 / (cos_sim_values.max() - cos_sim_values.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_graph.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_graph.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordsMMScoreList(score,scored_list):\n",
    "    word_list = list(scored_list[scored_list.iloc[:,1] >= score].iloc[:,0])\n",
    "    word_list.append(search_term)\n",
    "    return \"|\".join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsMMScoreList(100,word_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_matrix = pickle.load(open('./pkl_sets/score_matrix_seed_term_window_10E.pkl',\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_encoded[tweet_encoded.tweet_text.str.contains('pass')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_chart = pd.DataFrame(np.zeros((101,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(101):\n",
    "    min_max_chart.iloc[i] = len(tweet_encoded[tweet_encoded.tweet_text.str.contains(WordsMMScoreList(i,word_graph))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_chart.to_csv(r'./min_max_chart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_chart = min_max_chart/8048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.plot(min_max_chart);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_matrix.iloc[235:240,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all(score_matrix == score_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,top_num_words,10):\n",
    "#     print(str(i)+\": \",end=\"\")\n",
    "#     print(f1_score(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(i),flags=re.IGNORECASE)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(1),flags=re.IGNORECASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.title\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.title(\"Word Vector Analysis of Terms By Window Size Trained in 10 Epochs\")\n",
    "plt.xlabel(\"Number of Terms (Including Search Term)\")\n",
    "plt.ylabel(\"F1 Score: Identifying Relatedness by Term Inclusion\")\n",
    "# for i in (range(1,11)):\n",
    "#     plt.plot(score_matrix.iloc[1:,i-1],label=\"min count: \"+str(i))\n",
    "i=6\n",
    "plt.plot(score_matrix.iloc[1:,i-1],label=\"min count: \"+str(i))\n",
    "plt.axvline(238)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_df = pd.DataFrame(np.zeros((300,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    conf_df.iloc[i] = pd.Series(confusion_matrix(tweet_encoded.irma_rel,tweet_encoded.tweet_text.str.contains(WordsCWScoreList(i,5),flags=re.IGNORECASE)).ravel())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "plt.plot(conf_df.iloc[1:,3],label=\"True Positive\") \n",
    "plt.plot(conf_df.iloc[1:,2],label=\"False Negative\") \n",
    "plt.plot(conf_df.iloc[1:,1],label=\"False Positive\")\n",
    "plt.plot(conf_df.iloc[1:,0],label=\"True Negative\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 = true positive\n",
    "#0 = true negative\n",
    "#1 = false positive\n",
    "#2 = false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.subplots()\n",
    "\n",
    "color_list = [\"#562a72\", \"#862d63\", \"#aaa939\", \"#7e9f35\"]\n",
    "\n",
    "ax.stackplot(conf_df.iloc[1:,:].index, \n",
    "             conf_df.iloc[1:,3], \n",
    "             conf_df.iloc[1:,2], \n",
    "             conf_df.iloc[1:,1], \n",
    "             conf_df.iloc[1:,0], \n",
    "             labels=[\"True Positive\",\"False Negative\",\"False Positive\",\"True Negative\"],\n",
    "            colors = color_list)\n",
    "# ax.axhline(hc_encoded_counts[1],linestyle=\"-.\",color=\"w\")\n",
    "ax.axvline(238,linestyle=\"-.\",color=\"k\",label=\"Optimal F1 Score\")\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the chart below, an increase in x represents a longer list of words whose inclusion would indicate an 'irma-related' tweet within the model. By allowing more words into this list, there is a larger number of tweets evaluated as a true positive result, but it also increases the false positives. The objective is to maximize the number of true positives, while minimizing false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16,8))\n",
    "# ax = fig.subplots()\n",
    "\n",
    "# color_list = [\"#562a72\", \"#862d63\", \"#aaa939\", \"#7e9f35\"]\n",
    "\n",
    "# ax.stackplot(score_matrix.iloc[1:,:].index, \n",
    "#              score_matrix.iloc[1:,:].TruePos, \n",
    "#              score_matrix.iloc[1:,:].FalseNeg, \n",
    "#              score_matrix.iloc[1:,:].FalsePos, \n",
    "#              score_matrix.iloc[1:,:].TrueNeg,\n",
    "#              labels=[\"True Positive\",\"False Negative\",\"False Positive\",\"True Negative\"],\n",
    "#             colors = color_list)\n",
    "# ax.axhline(hc_encoded_counts[1],linestyle=\"-.\",color=\"w\")\n",
    "# ax.legend(loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(score_matrix.iloc[ceil(related_words.iloc[50].score)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
