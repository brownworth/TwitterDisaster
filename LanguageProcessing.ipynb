{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Language Processing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tweet_id','timestamp','tweet_text','user_id',\n",
    "           'tweet_coords','tweet_coords_list','tweet_long','tweet_lat','location',\n",
    "           'enc_url','tweet_lang','hashtags']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%timeit` has the following command at:\n",
    "`3.02 s ± 29 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)`\n",
    "This is much faster than attempting to explicitly define the string for date formatting, and using `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_data = pd.read_csv(r'./tweetCoords.csv',header=None,names=columns,parse_dates=[1],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_string = \"2017-09-01 00:00:00\"\n",
    "delta_hours = 1\n",
    "start_time = pd.to_datetime(time_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting information in a single hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_hour = tweet_data[(tweet_data['timestamp'] >= start_time) &\n",
    "                        (tweet_data['timestamp'] <= start_time + pd.Timedelta(hours=delta_hours))].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing extraneous columns for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_hour.drop(columns=tweet_hour.columns[3:],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id      1365\n",
       "timestamp     1365\n",
       "tweet_text    1365\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hour.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on functionality to clean tweet text.\n",
    "- Eliminate links.\n",
    "- Drop user mentions.\n",
    "- *amp* as ampersand (this may need to be removed later)\n",
    "- remove non-word characters (ascii x21-x40, x5B-x60, x7B-x7F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of manual cleaning, working with the nltk tweet tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing the difference. Notice how it reduced the length of consecutive characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YOOOOOOOOOOOOOOO',\n",
       " 'CHILLLL',\n",
       " 'that',\n",
       " 's',\n",
       " 'not',\n",
       " 'happening',\n",
       " 'https://t.co/KGhi654L0L']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hour.loc[1340,'tweet_text'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YOOO', 'CHILLL', 'that', 's', 'not', 'happening', 'https://t.co/KGhi654L0L']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokenizer.tokenize(tweet_hour.loc[1340,'tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                        [Ocala, :, 7:50, pm, :, sunset]\n",
       "1    [Wind, 2.0, mph, ESE, ., Barometer, 30.013, in, ,, Steady, ., Temperature, 85.2, F, ., Rain, tod...\n",
       "2                                                               [Where, words, fall, ..., music, speaks]\n",
       "3                      [First, with, my, bride, #lovetampa, #bucs, #buccaneers, https://t.co/miYlZw6YEX]\n",
       "4    [Wow, ., That, was, rough, ., It, s, basically, drinking, a, shot, of, whiskey, beer, ..., 120, ...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hour['tweet_text'].apply(tweet_tokenizer.tokenize).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english')) | set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vector = CountVectorizer(analyzer='word',stop_words=stopWords).fit(tweet_hour['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5488"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_vector.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\fbbigger\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_model = models.Word2Vec(sentences=tweet_hour['tweet_text'].apply(tweet_tokenizer.tokenize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m', 0.9883741140365601),\n",
       " ('re', 0.9883188605308533),\n",
       " ('an', 0.988035261631012),\n",
       " ('en', 0.9878236055374146),\n",
       " ('now', 0.9877570271492004),\n",
       " ('he', 0.9876581430435181),\n",
       " ('gt', 0.9876514673233032),\n",
       " ('I', 0.9876255989074707),\n",
       " ('me', 0.987604022026062),\n",
       " ('we', 0.9875683784484863)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_model.wv.similar_by_word('Sheeran')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                           [Ocala, :, 7:50, pm, :, sunset]\n",
       "1       [Wind, 2.0, mph, ESE, ., Barometer, 30.013, in, ,, Steady, ., Temperature, 85.2, F, ., Rain, tod...\n",
       "2                                                                  [Where, words, fall, ..., music, speaks]\n",
       "3                         [First, with, my, bride, #lovetampa, #bucs, #buccaneers, https://t.co/miYlZw6YEX]\n",
       "4       [Wow, ., That, was, rough, ., It, s, basically, drinking, a, shot, of, whiskey, beer, ..., 120, ...\n",
       "5       [I, can, t, even, watch, #Diana20, programmes, because, it, s, just, so, sad, She, was, an, incr...\n",
       "6                                                                     [Gainesville, :, 7:51, pm, :, sunset]\n",
       "7        [Exactly, 4hrs, til, my, blessings, ..., @, The, World, Famous, Original, https://t.co/RzaIK0aEIM]\n",
       "8       [I, m, at, Louis, Pappas, Market, Cafe, :, Shoppes, at, Citrus, Park, in, Tampa, ,, FL, https://...\n",
       "9       [Don, t, try, amp, talk, 2, me, when, it, s, convenient, 4, U, .., I, ll, leave, you, right, whe...\n",
       "10      [#Repost, Great, shoot, today, ,, with, lululemon, ambassador, ,, dragonflyogi, ., Such, an, hon...\n",
       "11                               [She, s, only, loyal, to, l, Jefe, I, bet, she, tastes, like, Tres, Leche]\n",
       "12                                                                 [Pinellas, Park, :, 7:51, pm, :, sunset]\n",
       "13                                  [#GalationsSixAndNine, @, Spring, Hill, ,, FL, https://t.co/8dBicwcPFh]\n",
       "14      [There, s, more, #traveling, in, middle, school, girl, s, #basketball, than, on, https://t.co/qS...\n",
       "15                                                    [There, s, simply, no, limit, to, this, sociopath, .]\n",
       "16      [If, she, cant, do, this, on, da, i, dont, want, her, #MoonWalkin, @, Tallahassee, ,, Florida, h...\n",
       "17      [Severe, Thunderstorm, Warning, including, Monticello, FL, ,, Greenville, FL, ,, Waukeenah, FL, ...\n",
       "18      [Severe, Thunderstorm, Warning, including, Monticello, FL, ,, Greenville, FL, ,, Waukeenah, FL, ...\n",
       "19      [#tbt, to, that, time, I, crashed, a, corporate, yacht, party, in, Miami, ., https://t.co/hiyuzM...\n",
       "20      [not, the, best, but, this, pic, for, idc, Im, not, watching, no, bortles, or, henne, Tulsa, HVA...\n",
       "21      [omg, i, told, someone, i, d, go, to, there, party, tonight, and, all, i, wanna, do, is, play, s...\n",
       "22                                                [I, m, at, in, Kissimmee, ,, FL, https://t.co/gRSsKSg2de]\n",
       "23                                                                        [Dunedin, :, 7:51, pm, :, sunset]\n",
       "24                                                       [I, ll, win, regular, season, and, finals, MVP, .]\n",
       "25                                                [I, truly, get, excited, when, landing, in, a, new, city]\n",
       "26      [08/31, /, 17, -, Personal, Picks, :, NCAAF, OSU, RL, -20.5, -, 115, #pending, #NCAAF, #PERSONAL...\n",
       "27      [Bahhahs, this, guy, told, me, that, since, I, moved, to, Florida, I, shouldn, t, worry, about, ...\n",
       "28      [Art, gallery, idea, :, someone, just, takes, a, bunch, of, photos, of, all, the, bare, feet, at...\n",
       "29                                                                            [Miami, central, 12, BTW, 10]\n",
       "                                                       ...                                                 \n",
       "1335                                   [OSU, is, overrated, ., But, they, re, just, preseason, rankings, .]\n",
       "1336                          [#tlmgirls, #roadracing, carterfartuch, 24, #racing, https://t.co/8JlbRLS8oJ]\n",
       "1337    [has, lied, about, everything, ,, from, crowd, sizes, to, meetings, with, russians, ., The, alle...\n",
       "1338                                                     [Ok, little, guy, ,, we, see, you, Grant, BALLING]\n",
       "1339                                           [I, m, at, in, Bal, Harbour, ,, FL, https://t.co/VVNqlbJcgV]\n",
       "1340                                       [YOOO, CHILLL, that, s, not, happening, https://t.co/KGhi654L0L]\n",
       "1341                                                                 [Motherfucking, Grant, baby, #PhinsUp]\n",
       "1342    [Back, from, its, final, deployment, ,, the, USS, Jacksonville, has, returned, to, its, homeport...\n",
       "1343                                                     [Why, is, Princess, Diana, so, fondly, remembered]\n",
       "1344                         [We, are, Artium, Miami, Art, Gallery, #artcollector, https://t.co/ia3AS3URcn]\n",
       "1345                                             [Big, issue, ., Need, changes, ., https://t.co/kIM1qTDeFl]\n",
       "1346                                                    [weekends, dedicated, to, college, football, again]\n",
       "1347                                    [Day, is, done, .., @, Glades, Boat, Yard, https://t.co/x5iDMWdB4s]\n",
       "1348                                                                [Everytime, I, drink, I, get, nauseous]\n",
       "1349                                              [amp, his, parents, ,, See, yah, https://t.co/721nWpNHJf]\n",
       "1350                                                                          [Always, in, the, dog, house]\n",
       "1351                                                                [Thank, you, Larry, for, your, service]\n",
       "1352                                                [They, need, to, keep, David, Fales, end, of, story, .]\n",
       "1353    [Gana, tus, 3, primeros, viajes, gratis, en, UBER, reg, strate, con, el, c, digo, kbjcg, C, DIGO...\n",
       "1354    [Hoy, en, el, Peri, dico, #EsikaPro, #Colombia, #MiPatria, @, Miami, ,, Florida, https://t.co/gy...\n",
       "1355    [Lo, digo, ahora, y, siempre, lo, dir, :, vivir, en, valencia, es, lo, m, s, t, xico, que, puede...\n",
       "1356    [Drew, Baldrich, ,, killing, it, on, the, WON, Waterfront, ., #country, #music, #band, #guitaris...\n",
       "1357                                                             [Run, the, whole, https://t.co/ORfze0riqt]\n",
       "1358                                                             [This, lady, named, her, daughter, Vision]\n",
       "1359                    [Go, Buccaneers, #siegetheday, @, Raymond, James, Stadium, https://t.co/PcU0vQICJb]\n",
       "1360               [Great, with, wings, ., -, Drinking, an, All, Day, IPA, by, at, https://t.co/ULHL8Hmi15]\n",
       "1361                                                                    [JUN, 19R, https://t.co/IOmfsIZTWG]\n",
       "1362    [Artist, guest, room, #libeco, #seanrush, #seanrushatelier, #dropclothcurtains, #bedroom, #bedro...\n",
       "1363    [#tbt, to, this, eVite, created, for, the, Circle, of, Friendship, of, Greater, Fort, Lauderdale...\n",
       "1364    [Que, es, lo, m, s, importante, del, #Liderazgo, Lo, m, s, importante, del, #Liderazgo, es, cono...\n",
       "Name: tweet_text, Length: 1365, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_hour['tweet_text'].map(tweet_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-8fef1e38e48f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_hour\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\fbbigger\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\probability.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \"\"\"\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mCounter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Cached number of samples in this FreqDist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fbbigger\\appdata\\local\\programs\\python\\python36\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fbbigger\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\nltk\\probability.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \"\"\"\n\u001b[0;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\fbbigger\\appdata\\local\\programs\\python\\python36\\lib\\collections\\__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# fast path when counter is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m                 \u001b[0m_count_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "nltk.FreqDist(list(tweet_hour['tweet_text'].apply(tweet_tokenizer.tokenize)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
