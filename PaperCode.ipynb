{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize.casual import reduce_lengthening\n",
    "from scipy.spatial.distance import cosine\n",
    "import re\n",
    "import string\n",
    "from math import sqrt\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['tweet_id','timestamp','tweet_text','user_id',\n",
    "           'tweet_coords','tweet_coords_list','tweet_long','tweet_lat','location',\n",
    "           'enc_url','tweet_lang','hashtags']\n",
    "tweet_full = pd.read_csv(r'./tweetCoords.csv',\n",
    "                         header=None,\n",
    "                         names=columns,\n",
    "                         parse_dates=[1],\n",
    "                         infer_datetime_format=True,\n",
    "                         index_col='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_date = pd.to_datetime(\"2017-09-10 00:00:00\")\n",
    "date_delta = pd.Timedelta(\"24HR\")\n",
    "end_date = pd.to_datetime(\"2017-09-10 00:00:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_full_en = tweet_full[tweet_full['tweet_lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = 'irma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coded_tweets = pd.read_csv(r'./irma_related_tweets.csv')\n",
    "\n",
    "tweets_on_date = tweet_full_en.loc[tweet_date:tweet_date+date_delta]\n",
    "\n",
    "tweet_encoded = pd.concat([coded_tweets.reset_index(),tweets_on_date.iloc[:-1].reset_index()],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_stops = stopwords.words('english')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "##     takes input string and converts or removes characters depending on settings.\n",
    "##     returns a string\n",
    "##     convert case:\n",
    "    tweet = tweet.lower()\n",
    "##    remove URLs:\n",
    "    tweet = re.sub('https?://\\S+','',tweet)\n",
    "##     remove @mentions, including those with a leading '-' or '.' : \n",
    "    tweet = re.sub('[-\\.]?@\\w+','',tweet)\n",
    "##     remove non-hashtag punctuation:\n",
    "#     tweet = tweet.translate(tweet.maketrans('','',string.punctuation.replace(\"#\",\"\")))\n",
    "##     convert non-hashtag punctuation to whitespace:\n",
    "    tweet = tweet.translate(tweet.maketrans(string.punctuation.replace(\"#\",\"\"),\" \"*len(string.punctuation.replace(\"#\",\"\"))))\n",
    "#     remove non-hashtag '#'.\n",
    "    tweet = re.sub('\\B#\\B','',tweet)\n",
    "##     remove 'amp', 'gt', 'lt', indicating decoded ampersand, greater-than, less-than characters\n",
    "    tweet = re.sub(r'\\b(amp|gt|lt)\\b','',tweet)\n",
    "##     drop numbers and words of < 4 characters.\n",
    "#     tweet = re.sub(r'\\b(?<!#)\\w{1,3}\\b','',tweet)\n",
    "    tweet = re.sub(r'\\b(?<!#)\\d+\\b','',tweet)\n",
    "    return tweet\n",
    "\n",
    "def tokens_no_stopwords(tweet_as_string):\n",
    "#     wrapper function that combines the tokenizer, cleaner, and stopword removal.\n",
    "#     takes a string and returns a list of strings\n",
    "    cleaned_tweet = clean_tweet(tweet_as_string)\n",
    "    tweet_reduce_len = reduce_lengthening(cleaned_tweet)\n",
    "#     tweet_as_tokens = word_tokenize(tweet_reduce_len)\n",
    "    tweet_as_tokens = tweet_reduce_len.split()\n",
    "    tweet_no_stops = [stemmer.stem(word) for word in tweet_as_tokens if word not in tweet_stops]\n",
    "    \n",
    "    return tweet_no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanCosSim(tweet,vector_set):\n",
    "    tweet_as_terms = tokens_no_stopwords(tweet)\n",
    "    score = 0\n",
    "    for i in tweet_as_terms:\n",
    "        if i in vector_set.wv.vocab:\n",
    "            score += vector_set.wv.similarity(i,search_term)\n",
    "    if len(tweet_as_terms) > 0:\n",
    "        score /= len(tweet_as_terms)\n",
    "    else:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def sumCosSimSqrtSum(tweet,vector_set):\n",
    "    tweet_as_terms = tokens_no_stopwords(tweet)\n",
    "    score = 0\n",
    "    for i in tweet_as_terms:\n",
    "        if i in vector_set.wv.vocab:\n",
    "            score += vector_set.wv.similarity(i,search_term)\n",
    "    if len(tweet_as_terms) > 0:\n",
    "        score /= sqrt(len(tweet_as_terms))\n",
    "    else:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def dotProductOfTweetMatrixTermVector(tweet,vector_set):\n",
    "    tweet_as_terms = tokens_no_stopwords(tweet)\n",
    "#     initialize vector with dimensionality of the vector set.\n",
    "    vector_dim = len(vector_set.wv.vectors[0])\n",
    "    score_matrix = np.zeros(vector_dim,) \n",
    "#     iterate over each word after processing. If the word is in the vocabulary,\n",
    "#     add its vector's value to the score matrix.\n",
    "#     this essentially treats a word not in the vocabulary as a zero-vector.\n",
    "    for i in tweet_as_terms:\n",
    "        if i in vector_set.wv.vocab:\n",
    "            score_matrix = np.add(score_matrix,vector_set.wv.get_vector(i))\n",
    "#     if the number of words remaining in the tweet after processing is equal to zero, return zero.\n",
    "#     otherwise, take the dot product of the score vector, and the vector of the search term.\n",
    "    if len(tweet_as_terms) > 0:\n",
    "        score = np.dot(score_matrix,vector_set.wv.get_vector(search_term))\n",
    "    else:\n",
    "        score = 0\n",
    "    return score\n",
    "\n",
    "def cosSimOfTweetMatrixTermVector(tweet,vector_set):\n",
    "    tweet_as_terms = tokens_no_stopwords(tweet)\n",
    "#     initialize vector with dimensionality of the vector set.\n",
    "    vector_dim = len(vector_set.wv.vectors[0])\n",
    "    score_matrix = np.zeros(vector_dim,) \n",
    "#     iterate over each word after processing. If the word is in the vocabulary,\n",
    "#     add its vector's value to the score matrix.\n",
    "#     this essentially treats a word not in the vocabulary as a zero-vector.\n",
    "    for i in tweet_as_terms:\n",
    "        if i in vector_set.wv.vocab:\n",
    "            score_matrix = np.add(score_matrix,vector_set.wv.get_vector(i))\n",
    "#     if the number of words remaining in the tweet after processing is equal to zero, return zero.\n",
    "#     otherwise, take the pairwise cosine of the score vector and the vector of the search term.\n",
    "    if ((len(tweet_as_terms) > 0) & (np.all(score_matrix != np.zeros(vector_dim,)))):\n",
    "        score = 1 - cosine(score_matrix,vector_set.wv.get_vector(search_term))\n",
    "    else:\n",
    "        score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalarFunctions(tweet,vector_set,formula='dp'):\n",
    "    if(formula.upper() == 'DP'):\n",
    "        return dotProductOfTweetMatrixTermVector(tweet,vector_set)\n",
    "    elif(formula.upper() == 'MCS'):\n",
    "        return meanCosSim(tweet,vector_set)\n",
    "    elif(formula.upper() == 'SCSSC'):\n",
    "        return sumCosSimSqrtSum(tweet,vector_set)\n",
    "    elif(formula.upper() == 'CSTVS'):\n",
    "        return cosSimOfTweetMatrixTermVector(tweet,vector_set)\n",
    "    else:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2482287, 3224100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking values from tests for max AU-ROC\n",
    "HD=150\n",
    "MWC=5\n",
    "WWS=1\n",
    "NS=1\n",
    "EP=25\n",
    "tweet_text = tweet_full_en.loc[tweet_date:tweet_date + date_delta,\"tweet_text\"]\n",
    "tweets_tokens = tweet_text.apply(tokens_no_stopwords)\n",
    "\n",
    "opt_vector_model = Word2Vec(tweets_tokens, min_count=MWC, window=WWS, workers=1, size=HD, seed=1, sg=1, negative=NS)\n",
    "\n",
    "opt_vector_model.train(tweets_tokens, total_examples=len(tweet_text), epochs=EP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal parameters for Word2Vec:\n",
    "for i in ['dp','mcs','scssc','cstvs']:\n",
    "#     create strings for column heads\n",
    "    sw = f'o-sw-{i}'\n",
    "    mmsw = f'MM-{sw}'\n",
    "    \n",
    "#     Scoring tweets in this column:\n",
    "    tweet_encoded[sw] = tweet_encoded.tweet_text.apply(scalarFunctions,args=(opt_vector_model,i))\n",
    "                                                       \n",
    "#     column of scores for this iteration|\n",
    "    tweet_scores = tweet_encoded[sw]\n",
    "\n",
    "#     calculating Min Max Scaling for this column \n",
    "    tweet_encoded[mmsw] = ((tweet_scores - tweet_scores.min())* 100) / (tweet_scores.max() - tweet_scores.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>irma_rel</th>\n",
       "      <th>tweet</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_coords</th>\n",
       "      <th>tweet_coords_list</th>\n",
       "      <th>tweet_long</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>o-sw-dp</th>\n",
       "      <th>MM-o-sw-dp</th>\n",
       "      <th>o-sw-mcs</th>\n",
       "      <th>MM-o-sw-mcs</th>\n",
       "      <th>o-sw-scssc</th>\n",
       "      <th>MM-o-sw-scssc</th>\n",
       "      <th>o-sw-cstvs</th>\n",
       "      <th>MM-o-sw-cstvs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wind 2.0 mph N. Barometer 29.880 in, Steady. T...</td>\n",
       "      <td>2017-09-10 00:00:01</td>\n",
       "      <td>906668545542680576</td>\n",
       "      <td>Wind 2.0 mph N. Barometer 29.880 in, Steady. T...</td>\n",
       "      <td>1227982520</td>\n",
       "      <td>[28.87527778,-81.2525]</td>\n",
       "      <td>[[[-81.285896, 28.84511], [-81.285896, 28.9640...</td>\n",
       "      <td>-81.2525</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.236014</td>\n",
       "      <td>36.633941</td>\n",
       "      <td>0.109313</td>\n",
       "      <td>24.530168</td>\n",
       "      <td>0.345678</td>\n",
       "      <td>34.999933</td>\n",
       "      <td>0.151114</td>\n",
       "      <td>31.159563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>There is always beauty regardless the circumst...</td>\n",
       "      <td>2017-09-10 00:00:03</td>\n",
       "      <td>906668555185291265</td>\n",
       "      <td>There is always beauty regardless the circumst...</td>\n",
       "      <td>42239064</td>\n",
       "      <td>[29.5381,-81.2234]</td>\n",
       "      <td>[[[-81.279617, 29.424649], [-81.279617, 29.627...</td>\n",
       "      <td>-81.2234</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.228878</td>\n",
       "      <td>27.521331</td>\n",
       "      <td>0.155160</td>\n",
       "      <td>28.414881</td>\n",
       "      <td>0.410514</td>\n",
       "      <td>38.538043</td>\n",
       "      <td>0.329257</td>\n",
       "      <td>45.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>#Carpool #Orlando - gt  #Orlando #KIrkmanRoad ...</td>\n",
       "      <td>2017-09-10 00:00:03</td>\n",
       "      <td>906668556493889536</td>\n",
       "      <td>#Carpool #Orlando - gt  #Orlando #KIrkmanRoad ...</td>\n",
       "      <td>87188071</td>\n",
       "      <td>[28.4363045,-81.4797168]</td>\n",
       "      <td>[[[-87.634643, 24.396308], [-87.634643, 31.001...</td>\n",
       "      <td>-81.4797</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>Carpool,Orlando,Orlando,KIrkmanRoad</td>\n",
       "      <td>7.234932</td>\n",
       "      <td>20.252649</td>\n",
       "      <td>0.119459</td>\n",
       "      <td>25.389844</td>\n",
       "      <td>0.358376</td>\n",
       "      <td>35.692878</td>\n",
       "      <td>0.317292</td>\n",
       "      <td>44.635784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>@avictoria_x nah i m chillin my eyes never get...</td>\n",
       "      <td>2017-09-10 00:00:06</td>\n",
       "      <td>906668570079309830</td>\n",
       "      <td>@avictoria_x nah i m chillin my eyes never get...</td>\n",
       "      <td>746764728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[[-81.25235, 28.549308], [-81.25235, 28.58224...</td>\n",
       "      <td>-81.2380</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.916055</td>\n",
       "      <td>23.312167</td>\n",
       "      <td>0.200429</td>\n",
       "      <td>32.250661</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>42.927352</td>\n",
       "      <td>0.392980</td>\n",
       "      <td>50.773643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@jvnvy @sza That s how I feel bout seein travis</td>\n",
       "      <td>2017-09-10 00:00:08</td>\n",
       "      <td>906668576056246278</td>\n",
       "      <td>@jvnvy @sza That s how I feel bout seein travis</td>\n",
       "      <td>1679199278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[[-82.31457, 27.823335], [-82.31457, 27.85374...</td>\n",
       "      <td>-82.2877</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.208802</td>\n",
       "      <td>11.105471</td>\n",
       "      <td>0.077907</td>\n",
       "      <td>21.869098</td>\n",
       "      <td>0.155814</td>\n",
       "      <td>24.639194</td>\n",
       "      <td>0.176788</td>\n",
       "      <td>33.241585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  irma_rel                                              tweet  \\\n",
       "0      0         1  Wind 2.0 mph N. Barometer 29.880 in, Steady. T...   \n",
       "1      1         0  There is always beauty regardless the circumst...   \n",
       "2      2         0  #Carpool #Orlando - gt  #Orlando #KIrkmanRoad ...   \n",
       "3      3         0  @avictoria_x nah i m chillin my eyes never get...   \n",
       "4      4         0    @jvnvy @sza That s how I feel bout seein travis   \n",
       "\n",
       "            timestamp            tweet_id  \\\n",
       "0 2017-09-10 00:00:01  906668545542680576   \n",
       "1 2017-09-10 00:00:03  906668555185291265   \n",
       "2 2017-09-10 00:00:03  906668556493889536   \n",
       "3 2017-09-10 00:00:06  906668570079309830   \n",
       "4 2017-09-10 00:00:08  906668576056246278   \n",
       "\n",
       "                                          tweet_text     user_id  \\\n",
       "0  Wind 2.0 mph N. Barometer 29.880 in, Steady. T...  1227982520   \n",
       "1  There is always beauty regardless the circumst...    42239064   \n",
       "2  #Carpool #Orlando - gt  #Orlando #KIrkmanRoad ...    87188071   \n",
       "3  @avictoria_x nah i m chillin my eyes never get...   746764728   \n",
       "4    @jvnvy @sza That s how I feel bout seein travis  1679199278   \n",
       "\n",
       "               tweet_coords  \\\n",
       "0    [28.87527778,-81.2525]   \n",
       "1        [29.5381,-81.2234]   \n",
       "2  [28.4363045,-81.4797168]   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "\n",
       "                                   tweet_coords_list  tweet_long  ...  \\\n",
       "0  [[[-81.285896, 28.84511], [-81.285896, 28.9640...    -81.2525  ...   \n",
       "1  [[[-81.279617, 29.424649], [-81.279617, 29.627...    -81.2234  ...   \n",
       "2  [[[-87.634643, 24.396308], [-87.634643, 31.001...    -81.4797  ...   \n",
       "3  [[[-81.25235, 28.549308], [-81.25235, 28.58224...    -81.2380  ...   \n",
       "4  [[[-82.31457, 27.823335], [-82.31457, 27.85374...    -82.2877  ...   \n",
       "\n",
       "   tweet_lang                             hashtags    o-sw-dp MM-o-sw-dp  \\\n",
       "0          en                                  NaN  16.236014  36.633941   \n",
       "1          en                                  NaN  11.228878  27.521331   \n",
       "2          en  Carpool,Orlando,Orlando,KIrkmanRoad   7.234932  20.252649   \n",
       "3          en                                  NaN   8.916055  23.312167   \n",
       "4          en                                  NaN   2.208802  11.105471   \n",
       "\n",
       "   o-sw-mcs  MM-o-sw-mcs  o-sw-scssc  MM-o-sw-scssc  o-sw-cstvs  MM-o-sw-cstvs  \n",
       "0  0.109313    24.530168    0.345678      34.999933    0.151114      31.159563  \n",
       "1  0.155160    28.414881    0.410514      38.538043    0.329257      45.606061  \n",
       "2  0.119459    25.389844    0.358376      35.692878    0.317292      44.635784  \n",
       "3  0.200429    32.250661    0.490950      42.927352    0.392980      50.773643  \n",
       "4  0.077907    21.869098    0.155814      24.639194    0.176788      33.241585  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_encoded.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
